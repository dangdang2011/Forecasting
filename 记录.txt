** 20180613 **
 xgb = XGBClassifier(
        silent=0,  # 设置成1则没有运行信息输出，最好是设置为0.是否在运行升级时打印消息。
        # nthread=4,# cpu 线程数 默认最大
        learning_rate=0.3,  # 如同学习率
        min_child_weight=1,
        # 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言
        # ，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。
        # 这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。
        max_depth=6,  # 构建树的深度，越大越容易过拟合
        gamma=0.1,  # 树的叶子节点上作进一步分区所需的最小损失减少,越大越保守，一般0.1、0.2这样子。
        subsample=1,  # 随机采样训练样本 训练实例的子采样比
        max_delta_step=0,  # 最大增量步长，我们允许每个树的权重估计。
        colsample_bytree=1,  # 生成树时进行的列采样
        reg_lambda=1,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。
        # reg_alpha=0, # L1 正则项参数
        # scale_pos_weight=1, #如果取值大于0的话，在类别样本不平衡的情况下有助于快速收敛。平衡正负权重
        # objective= 'multi:softmax', #多分类的问题 指定学习任务和相应的学习目标
        # num_class=10, # 类别数，多分类与 multisoftmax 并用
        n_estimators=100,  # 树的个数
        seed=1000  # 随机种子
        # eval_metric= 'auc'
    )
线下：0.825左右
去掉PCA以后精度会降低

活跃用户有： 18223 人
不活跃的用户有： 19223 人 比例还是比较均匀的
数据本身的01分布不是很均匀




PCA降维后维度 (37446, 4)
单个变量方差贡献率 [ 0.94164708  0.04487934  0.00779155  0.00387516]
            user_id  register_day  register_type   device type    app_launch  \
count  3.744600e+04  37446.000000   37446.000000  37446.000000  37446.000000   
mean   6.859060e+05     13.168055       0.917054    589.976980      2.207846   
std    3.962919e+05      6.630877       1.218721   4138.922691      2.413239   
min    1.600000e+01      1.000000       0.000000      0.000000      0.000000   
25%    3.436335e+05      7.000000       0.000000     11.000000      0.000000   
50%    6.848015e+05     13.000000       1.000000     46.000000      1.000000   
75%    1.029680e+06     19.000000       1.000000    208.000000      3.000000   
max    1.367532e+06     23.000000      11.000000  93497.000000      8.000000   

       action_type_0  action_type_1  action_type_2  action_type_3  \
count   37446.000000   37446.000000   37446.000000   37446.000000   
mean      179.041206       5.137024       1.899215       0.409149   
std       409.192113      27.114090       7.895596       2.796734   
min         0.000000       0.000000       0.000000       0.000000   
25%         0.000000       0.000000       0.000000       0.000000   
50%        13.000000       0.000000       0.000000       0.000000   
75%       159.000000       2.000000       1.000000       0.000000   
max      9751.000000    2794.000000     592.000000     199.000000   

       action_type_4      ...       launch_interval_mean  launch_interval_max  \
count   37446.000000      ...               37446.000000         37446.000000   
mean        0.001469      ...                   0.656194             0.801260   
std         0.135048      ...                   0.937603             1.173243   
min         0.000000      ...                   0.000000             0.000000   
25%         0.000000      ...                   0.000000             0.000000   
50%         0.000000      ...                   0.000000             0.000000   
75%         0.000000      ...                   1.000000             1.000000   
max        25.000000      ...                   7.000000             7.000000   

       launch_interval_min  launch_interval_var  launch_interval_cv  \
count         37446.000000         37446.000000        37446.000000   
mean              0.570288             0.105122            0.060508   
std               0.847995             0.465280            0.157437   
min               0.000000             0.000000            0.000000   
25%               0.000000             0.000000            0.000000   
50%               0.000000             0.000000            0.000000   
75%               1.000000             0.000000            0.000000   
max               7.000000             6.250000            0.808122   

       launch_continuous_count             0             1             2  \
count             37446.000000  3.744600e+04  3.744600e+04  3.744600e+04   
mean                  1.916787 -1.689390e-13  1.887380e-14 -9.130188e-14   
std                   2.230566  6.606477e+02  1.442278e+02  6.009491e+01   
min                   0.000000 -2.882588e+02 -2.480194e+03 -6.808515e+02   
25%                   0.000000 -2.882588e+02  5.084544e+00 -6.943141e+00   
50%                   1.000000 -2.679728e+02  1.294839e+01 -5.764646e+00   
75%                   3.000000 -3.411779e+01  1.358649e+01 -2.324753e+00   
max                   8.000000  1.540158e+04  3.193849e+03  2.308876e+03   

                  3  
count  3.744600e+04  
mean   5.146488e-15  
std    4.238096e+01  
min   -1.119169e+03  
25%    8.892874e-01  
50%    1.278735e+00  
75%    2.550662e+00  
max    2.258542e+03
** 20180612 **
权值，1-10号*0.1，11-17*0.3，18-23*0.6
数据分布
测试一下lightgbm




** 20180609 **
模型测试结果：
param_test = {
        'max_depth':[3,4,5,6],
        'min_child_weight':[1,2,3,4],
        # 'gamma': [i / 10.0 for i in range(2, 4)]
    }
Parameter: {'max_depth': 3, 'min_child_weight': 4} 0.73034260107
param_test = {
        'max_depth':[3,4,5,6],
        'min_child_weight':[5,6,7,8],
        # 'gamma': [i / 10.0 for i in range(2, 4)]
    }Parameter: {'min_child_weight': 8, 'max_depth': 4} 0.729386887058


param_test = {
        'max_depth':[4,5,6,7],
        'min_child_weight':[2,3,4,5],
        # 'gamma': [i / 10.0 for i in range(2, 4)]
    }
Parameter: {'max_depth': 4, 'min_child_weight': 2} 0.729914246946


 param_test = {
        'max_depth':[3,4,5,6,7,8,9,10],
        'min_child_weight':[1,2,3,4,5,6,7,8],
        # 'gamma': [i / 10.0 for i in range(2, 4)]
    }

Parameter: {'min_child_weight': 3, 'max_depth': 3} 0.729241302797





** 20180607 **
修正了预处理部分的问题，准确率提高到0.72左右
比较了xgboost和gbdt的性能，增加了模型筛选模块。目前GBDT更合适一些。
eg显示如下：

1-23日活跃用户有： 18223
在这里使用了模型： XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,
       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1)
预测数据有： 17241
真实数据有： 18223
precision is: 0.7397482744620382 recall is: 0.699884761016298
正阳例，预测出真正的活跃用户有： 12754 评分： 0.7192646063613805
在这里使用了模型： GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
预测数据有： 17391
真实数据有： 18223
precision is: 0.7397504456327986 recall is: 0.7059759644405422
正阳例，预测出真正的活跃用户有： 12865 评分： 0.7224686920873814

提出疑问：add_feature第13行的14是怎么来的？这里有报错： ('string index out of range', 'occurred at index 14')

报错完整信息如下：
 File "/Users/lixuefei/PycharmProjects/bigdata/addFeature.py", line 47, in AddFeature
    min_action_type = pd.DataFrame(train_feature.iloc[:, [5, 6, 7, 8, 9, 10]]).apply(Min_action_type, axis=1)
  File "/Users/lixuefei/anaconda/lib/python3.5/site-packages/pandas/core/frame.py", line 4877, in apply
    ignore_failures=ignore_failures)
  File "/Users/lixuefei/anaconda/lib/python3.5/site-packages/pandas/core/frame.py", line 4973, in _apply_standard
    results[i] = func(v)
  File "/Users/lixuefei/PycharmProjects/bigdata/addFeature.py", line 16, in Min_action_type
    return str(x.idxmin())[14]
IndexError: ('string index out of range', 'occurred at index 0')


** 20180605 ** 
@糖糕补充了计算特征值的部分

** 20180604 **
1. 补充了预测部分和baseline计算部分。于label.py中。
2. 从特征到打标签到建模预测的过程如下:
   2.1 将数据集分成两部分，一部分（1-23日）用来建模，另一部分（24-30）用来验证。在1-23日注册的用户，如果在24-30日仍然出现活动则为活跃用户。因此将1-24日的注册文件的user_id与24-30所有活动日志的user_id进行比对，只要在后者出现过，则该user_id标注为1（活跃），否则为0（不活跃）
   2.2 timeInterval函数负责数据抽取和特征提取，特征有除了我们之前提到的8个（launch video_create和6种action以外），还有register的三个特征，但是目前建模先不用（used_feature = [4,5,6,7,8,9,10,11]）。
   2.3 用1-23作为训练集。注意，为了验证本阶段模型的好坏，需要将训练集分为测试集和验证集，可以用来测试模型的好坏。
   2.4 用24-30作为真实的结果。注意，在2.3验证部分，我们使用1-23日数据和评分准则计算模型的好坏，等模型测试好了以后，将1-23作为测试集，24-30作为验证集，验证最终的结果。
   2.5 2.3的验证部分大家觉得有必要吗？因为验证模型时，将模型随机划分为测试集和训练集是一种基本的交叉验证方法。但是我认为其实只有2.4作为验证好像也足够了。 详情可以参考 https://mp.weixin.qq.com/s/-Av2AusdG1HUBtyxNRJebA
   2.6 我们最终的上传结果，就是用1-30日的数据输入模型以后，user_id对应的label。


** 20180601 ** 
1. action_type.csv 文件时action种类的预处理结果。
action种类共6种，播放，关注，点赞，转发，举报，减少此类作品
# action_type
# 0    19798261
# 1      555671
# 2      206079
# 3       46078
# 4         157
# 5         982
举报是最少的（157）。产生action的用户数量为43710位。
2. app_launch_res.csv  产生app_launch的用户有1322302位。
3. user_register_log.txt  用户数量51708。
# file = pd.DataFrame(pd.read_table('user_register_log.txt'))
4. video_create_log.txt 用户数量不多于35150。(7606)
5. 我们的数据集要从注册日志51708个人当中产生。
